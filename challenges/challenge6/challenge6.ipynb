{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 6: Actions\n",
    "## Introduction\n",
    "\n",
    "In this part of the challenge you will add another agent to the solution.\n",
    "\n",
    "This time will be an agent that performs actions on behalf of the user.\n",
    "\n",
    "## Step 1: Setup the final enviroment\n",
    "\n",
    "## Step 2: Build on top of the previous solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../lib')))\n",
    "\n",
    "## Import the necessary libraries\n",
    "\n",
    "import requests\n",
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from urllib.parse import quote_plus \n",
    "from its_a_rag import ingestion\n",
    "from sqlalchemy import create_engine\n",
    "from langchain.agents import AgentExecutor, create_sql_agent, create_openai_tools_agent\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Environment Variables\n",
    "\n",
    "**Important:** Make sure you update your `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dotenv, sys\n",
    "dotenv.load_dotenv(override=True)\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../lib')))\n",
    "\n",
    "\n",
    "# Setup environment\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_MODEL = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING = os.getenv(\"AZURE_OPENAI_EMBEDDING\")\n",
    "# Azure Search\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "AZURE_SEARCH_INDEX = os.getenv(\"AZURE_SEARCH_INDEX\")\n",
    "# Azure AI Document Intelligence\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_KEY\")\n",
    "# Azure Blob Storage\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "AZURE_STORAGE_CONTAINER = os.getenv(\"AZURE_STORAGE_CONTAINER\")\n",
    "AZURE_STORAGE_FOLDER = os.getenv(\"AZURE_STORAGE_FOLDER\")\n",
    "\n",
    "# Local Folder for the documents\n",
    "LOCAL_FOLDER = \"../../data/fsi/pdf\"\n",
    "\n",
    "# SQL Database\n",
    "SQL_SERVER = os.getenv(\"SQL_SERVER\")\n",
    "SQL_DB = os.getenv(\"SQL_DB\")\n",
    "SQL_USERNAME = os.getenv(\"SQL_USERNAME\")\n",
    "SQL_PWD = os.getenv(\"SQL_PWD\")\n",
    "\n",
    "# STOCK API\n",
    "MOCK_API_ENDPOINT= os.getenv(\"MOCK_API_ENDPOINT\")\n",
    "\n",
    "# Define the questions list (if you are using your own dataset you need to change this list)\n",
    "QUESTIONS = [\n",
    "  \"What are the revenues of GOOGLE in the year 2009?\",\n",
    "  \"What are the revenues and the operative margins of ALPHABET Inc. in 2022 and how it compares with the previous year?\",\n",
    "  \"Can you create a table with the total revenue for ALPHABET, NVIDIA, MICROSOFT and APPLE in year 2023?\",\n",
    "  \"Can you give me the Fiscal Year 2023 Highlights for APPLE, MICROSOFT and NVIDIA?\",\n",
    "  \"Did APPLE repurchase common stock in 2023? create a table of APPLE repurchased stock with date, numbers of stocks and values in dollars.\",\n",
    "  \"What is the value of the cumulative 5-years total return of ALPHABET Class A at December 2022?\",\n",
    "  \"What was the price of APPLE, NVIDIA and MICROSOFT stock in 23/07/2024?\",\n",
    "  \"Can you buy 10 shares of APPLE for me?\"\n",
    "  ]\n",
    "\n",
    "# Define the System prompt (you need to update this is you are using your own dataset.)\n",
    "system_prompt_RAG = \"\"\" You are a financial assistant tasked with answering questions related to the financial results of major technology companies listed on NASDAQ, \\n\n",
    "specifically Microsoft (MSFT), Alphabet Inc. (GOOGL), Nvidia (NVDA), Apple Inc. (AAPL), and Amazon (AMZN). \\n\n",
    "if you don't find the answer in the context, just say `I don't know.`\"\"\"\n",
    "\n",
    "system_prompt_START = \"\"\"\n",
    "  You are an agent that needs analyze the user question. \\n\n",
    "  Question : {input} \\n\n",
    "  if the question is related to stock prices answer with \"stock\". \\n\n",
    "  if the question is related to information about financial results answer with \"rag\". \\n\n",
    "  if the question is a direct requesto for trading, buying or selling stocks answer with \"trade\". \\n\n",
    "  if the question is unclear or you cannot decide answer with \"rag\". \\n\n",
    "  only answer with one of the words provided.\n",
    "  Your answer (stock/rag/trade):\n",
    "  \"\"\"\n",
    "system_prompt_SQL = \"\"\"\n",
    "  You are a helpful AI assistant expert in querying SQL Database to find answers to user's question about stock prices.\n",
    "  If you can't find the answer, say 'I am unable to find the answer.'\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Build on top of the previous solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Azure OpenAI Chat Client\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    temperature=0,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Agent State Class to store the messages between the agents\n",
    "# this should include the input, output and decision as strings\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    decision: str\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': 'On 23/07/2024, the stock prices were as follows:\\n- APPLE (AAPL): $225.01\\n- NVIDIA (NVDA): $122.59\\n- MICROSOFT (MSFT): $444.85', 'input': 'What was the price of APPLE, NVIDIA and MICROSOFT stock in 23/07/2024?'}\n"
     ]
    }
   ],
   "source": [
    "# Stock Agent\n",
    "\n",
    "def stock_agent(state):\n",
    "    from langchain.agents import AgentType\n",
    "    # Import the LLM (you can use \"global\" to import the LLM in previous step to avoid re-creating the LLM objects)\n",
    "    global llm\n",
    "\n",
    "    # Create the SQL Database Object and the SQL Database Toolkit Object to be used by the agent.\n",
    "    engine = create_engine(\n",
    "        f\"mssql+pymssql://{SQL_USERNAME}:{SQL_PWD}@{SQL_SERVER}:1433/{SQL_DB}\")\n",
    "\n",
    "    db = SQLDatabase(engine=engine)\n",
    "    stock_toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "    # Create the agent using the Langhcain SQL Agent Class (create_sql_agent)\n",
    "    stock_agent = create_sql_agent(llm=llm,\n",
    "                                   toolkit=stock_toolkit,\n",
    "                                   agent_type=\"openai-tools\",\n",
    "                                   agent_name=\"StockAgent\",\n",
    "                                   agent_description=\"This agent is an expert in querying SQL Database to find answers to user's question about stock prices.\",\n",
    "                                   agent_version=\"0.1\",\n",
    "                                   agent_author=\"itsarag\",\n",
    "                                   # verbose=True,\n",
    "                                   agent_executor_kwargs=dict(handle_parsing_errors=True))\n",
    "    # Structure the final prompt from the ChatPromptTemplate\n",
    "    sql_prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", system_prompt_SQL),\n",
    "         (\"user\", \"{question}\\n ai:\")])\n",
    "    # Prepare the response using the invoke method of the agent\n",
    "    response = stock_agent.invoke(sql_prompt.format(\n",
    "        question=state[\"input\"]))\n",
    "    # Return the response for the next agent (output and input required coming fron the Agent State)\n",
    "    return {\"output\": response['output'], \"input\": state[\"input\"]}\n",
    "\n",
    "\n",
    "test_stock_state = AgentState(\n",
    "    input=QUESTIONS[6], output=\"\", decision=\"\", messages=[])\n",
    "result = stock_agent(test_stock_state)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did APPLE repurchase common stock in 2023? create a table of APPLE repurchased stock with date, numbers of stocks and values in dollars.\n",
      "{'output': 'Yes, Apple repurchased common stock in 2023. Here is a table summarizing the repurchased stock:\\n\\n| Date       | Number of Stocks (in thousands) | Value (in dollars) |\\n|------------|---------------------------------|---------------------|\\n| 2023       | 471,419                         | $76.6 billion       |\\n\\nNote: The specific dates of the repurchases within 2023 are not provided in the context.', 'input': 'Did APPLE repurchase common stock in 2023? create a table of APPLE repurchased stock with date, numbers of stocks and values in dollars.'}\n"
     ]
    }
   ],
   "source": [
    "# Node rag (this is a clean implementation of the RAG Agent completed in Challenge 4)\n",
    "def rag_agent(state):\n",
    "    # Import the LLM (you can use \"global\" to import the LLM in previous step to avoid re-creating the LLM objects)\n",
    "    global llm\n",
    "    rag_agent_llm = llm\n",
    "    # Define the index (use the one created in the previous challenge)\n",
    "    retriever_multimodal = AzureAISearchRetriever(\n",
    "        index_name=AZURE_SEARCH_INDEX, api_key=AZURE_SEARCH_API_KEY, service_name=AZURE_SEARCH_ENDPOINT, top_k=5)\n",
    "    # Define the chain (as it was in the previous challenge)\n",
    "    chain_multimodal_rag = (\n",
    "        {\n",
    "            \"context\": retriever_multimodal | RunnableLambda(ingestion.get_image_description),\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | RunnableLambda(ingestion.multimodal_prompt)\n",
    "        | rag_agent_llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    # prepare the response using the invoke method of the agent\n",
    "    response = chain_multimodal_rag.invoke({\"input\": state[\"input\"]})\n",
    "    # Return the response for the next agent (output and input required coming from the Agent State)\n",
    "    return {\"output\": response, \"input\": state[\"input\"]}\n",
    "\n",
    "\n",
    "print(QUESTIONS[4])\n",
    "test_rag_state = AgentState(\n",
    "    input=QUESTIONS[4], output=\"\", decision=\"\", messages=[])\n",
    "result = rag_agent(test_rag_state)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the Stock Action Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you buy 10 shares of APPLE for me?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `buy_stocks` with `{'quantity': 10, 'symbol': 'AAPL'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mBought 10 shares of AAPL\u001b[0m\u001b[32;1m\u001b[1;3mI have successfully bought 10 shares of APPLE (AAPL) for you.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'output': 'I have successfully bought 10 shares of APPLE (AAPL) for you.', 'input': 'Can you buy 10 shares of APPLE for me?'}\n"
     ]
    }
   ],
   "source": [
    "## Node stock_action\n",
    "# Define the tool using the @tool decorator\n",
    "@tool\n",
    "def buy_stocks(quantity: int, symbol: str) -> str:\n",
    "    \"\"\"\n",
    "    Permits to buy a quantity of shares of a specific stock.\n",
    "    \"\"\"\n",
    "    if not symbol or not quantity:\n",
    "        return f\"Missing required arguments: symbol and quantity are required.\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{MOCK_API_ENDPOINT}/api/buy/?stock_symbol={symbol}&quantity={quantity}\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"message\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Failed to buy stock. Exception: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def sell_stocks(quantity: int, symbol: str) -> str:\n",
    "    \"\"\"\n",
    "    Permits to sell a quantity of shares of a specific stock.\n",
    "    \"\"\"\n",
    "    if not symbol or not quantity:\n",
    "        return f\"Missing required arguments: symbol and quantity are required.\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{MOCK_API_ENDPOINT}/api/sell/?stock_symbol={symbol}&quantity={quantity}\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"message\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Failed to sell stock. Exception: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "# You can combine multiple tools in a single block called Toolkit\n",
    "stock_toolkit = [buy_stocks, sell_stocks]\n",
    "\n",
    "\n",
    "def stock_action(state):\n",
    "    # Define the LLM\n",
    "    global llm\n",
    "    stock_action_llm = llm\n",
    "    # Prepare the prompt for the agent (the create_openai_tools_agent function requires a ChatPromptTemplate object)\n",
    "    # Prompt Example: \"You are an agent that helps to acquire stocks. Use your tools to perform the requested action. \\n if you can't perform the action, say 'I am unable to perform the action.' \\n\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\",\n",
    "             \"\"\"\n",
    "            You are an agent that helps to acquire stocks. Use your tools to perform the requested action. \\n\n",
    "            If you can't perform the action, say 'I am unable to perform the action.'\n",
    "            \"\"\"\n",
    "             ),\n",
    "            MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "            (\"human\", \"{input}\"),\n",
    "            MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    # Construct the OpenAI Tools Agent\n",
    "    stock_buyer = create_openai_tools_agent(\n",
    "        stock_action_llm, stock_toolkit, prompt)\n",
    "    # Prepare the Agent Executor\n",
    "    stock_buyer_executor = AgentExecutor(\n",
    "        agent=stock_buyer, tools=stock_toolkit, verbose=True)\n",
    "    # prepare the response using the invoke method of the agent\n",
    "    response = stock_buyer_executor.invoke({\"input\": state[\"input\"]})\n",
    "    # Return the response for the next agent (output and input required coming from the Agent State)\n",
    "    return {\"output\": response['output'], \"input\": state[\"input\"]}\n",
    "\n",
    "# Test the stock_action agent\n",
    "print(QUESTIONS[7])\n",
    "test_stock_action_state = AgentState(\n",
    "    input=QUESTIONS[7], output=\"\", decision=\"\", messages=[])\n",
    "result = stock_action(test_stock_action_state)\n",
    "print(result)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Update the Start Agent adding an addition decision answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the revenues of GOOGLE in the year 2009?\n",
      "{'decision': 'rag', 'input': 'What are the revenues of GOOGLE in the year 2009?'}\n",
      "\n",
      "What are the revenues and the operative margins of ALPHABET Inc. in 2022 and how it compares with the previous year?\n",
      "{'decision': 'rag', 'input': 'What are the revenues and the operative margins of ALPHABET Inc. in 2022 and how it compares with the previous year?'}\n",
      "\n",
      "Can you create a table with the total revenue for ALPHABET, NVIDIA, MICROSOFT and APPLE in year 2023?\n",
      "{'decision': 'rag', 'input': 'Can you create a table with the total revenue for ALPHABET, NVIDIA, MICROSOFT and APPLE in year 2023?'}\n",
      "\n",
      "Can you give me the Fiscal Year 2023 Highlights for APPLE, MICROSOFT and NVIDIA?\n",
      "{'decision': 'rag', 'input': 'Can you give me the Fiscal Year 2023 Highlights for APPLE, MICROSOFT and NVIDIA?'}\n",
      "\n",
      "Did APPLE repurchase common stock in 2023? create a table of APPLE repurchased stock with date, numbers of stocks and values in dollars.\n",
      "{'decision': 'rag', 'input': 'Did APPLE repurchase common stock in 2023? create a table of APPLE repurchased stock with date, numbers of stocks and values in dollars.'}\n",
      "\n",
      "What is the value of the cumulative 5-years total return of ALPHABET Class A at December 2022?\n",
      "{'decision': 'rag', 'input': 'What is the value of the cumulative 5-years total return of ALPHABET Class A at December 2022?'}\n",
      "\n",
      "What was the price of APPLE, NVIDIA and MICROSOFT stock in 23/07/2024?\n",
      "{'decision': 'stock', 'input': 'What was the price of APPLE, NVIDIA and MICROSOFT stock in 23/07/2024?'}\n",
      "\n",
      "Can you buy 10 shares of APPLE for me?\n",
      "{'decision': 'trade', 'input': 'Can you buy 10 shares of APPLE for me?'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the start_agent that analyze the user question and decide if the question is related to stock prices or financial results\n",
    "def start_agent(state):\n",
    "    # Import the LLM (you can use \"global\" to import the LLM in previous step to avoid re-creating the LLM objects)\n",
    "    global llm\n",
    "    start_agent_llm = llm\n",
    "    # Prepare the prompt for the agent\n",
    "    # Prompt Example: You are an agent that needs analyze the user question. \\n Question : {input} \\n if the question is related to stock prices answer with \"stock\". \\n if the question is related to information about financial results answer with \"rag\". \\n if the question is unclear or you cannot decide answer with \"rag\". \\n only answer with one of the word provided. Your answer (stock/rag):\n",
    "    start_prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", system_prompt_START)])\n",
    "\n",
    "    # Prepare the chain to be executed\n",
    "    chain = start_prompt | start_agent_llm\n",
    "    # invoke the chain\n",
    "    response = chain.invoke({\"input\": state[\"input\"]})\n",
    "    # take the decision from the response\n",
    "    decision = response.content.strip().lower()\n",
    "    # Return the response for the next agent (decision and input required coming fron the Agent State)\n",
    "    return {\"decision\": decision, \"input\": state[\"input\"]}\n",
    "\n",
    "\n",
    "for QUESTION in QUESTIONS:\n",
    "    print(QUESTION)\n",
    "    test_start_state = AgentState(\n",
    "        input=QUESTION, output=\"\", decision=\"\", messages=[])\n",
    "    result = start_agent(test_start_state)\n",
    "    print(result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Update the previous graph to include the new agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 3 steps graph that is going to be working in the bellow \"decision\" condition\n",
    "# Add nodes (start_agent, stock_agent, rag_agent) and conditional edges where the decision with be stock or rag\n",
    "def create_graph():\n",
    "    # Create the Workflow as StateGraph using the AgentState\n",
    "    workflow = StateGraph(AgentState)\n",
    "    # Add the nodes (start_agent, stock_agent, rag_agent)\n",
    "    workflow.add_node(\"start\", start_agent)\n",
    "    workflow.add_node(\"stock_agent\", stock_agent)\n",
    "    workflow.add_node(\"trade_agent\", stock_action)\n",
    "    workflow.add_node(\"rag_agent\", rag_agent)\n",
    "    # Add the conditional edge from start -> lamba (decision) -> stock_agent or rag_agent\n",
    "    workflow.add_conditional_edges(\n",
    "        \"start\",\n",
    "        lambda x: x[\"decision\"],\n",
    "        {\n",
    "            \"stock\": \"stock_agent\",\n",
    "            \"rag\": \"rag_agent\",\n",
    "            \"trade\": \"trade_agent\"\n",
    "        }\n",
    "    )\n",
    "    # Set the workflow entry point\n",
    "    workflow.set_entry_point(\"start\")\n",
    "    # Add the final edges to the END node\n",
    "    workflow.add_edge(\"stock_agent\", END)\n",
    "    workflow.add_edge(\"rag_agent\", END)\n",
    "    workflow.add_edge(\"trade_agent\", END)\n",
    "    # Compile the workflow\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test the Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Solution\n",
    "\n",
    "# intantiate the graph (create_graph)\n",
    "graph = create_graph()\n",
    "\n",
    "# Use the graph invoke to answer the questions\n",
    "# Test the graph with various questions\n",
    "\n",
    "for QUESTION in QUESTIONS:\n",
    "    print (QUESTION)\n",
    "    result = graph.invoke({\"input\": QUESTION})\n",
    "    print(result[\"output\"])\n",
    "    print (\"------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
