{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Advanced RAG with Azure AI Document intelligence\n",
    "\n",
    "Many documents in  real scenario, are not just text, they are a combination of text, images, tables, etc. In this step, you will create a more advanced RAG application able to deal with this kind of documents.\n",
    "For this reason, you will use Azure AI Document Intelligence to extract the text, images, and tables from the documents and use them as input for the RAG model.\n",
    "\n",
    "To achieve this, we will build on top of the langchain framework enhancing the `Document Loader` and `Text Splitters` to deal with images and tables.\n",
    "In the code repositiory, you have already the enhanced version of the `Document Loader` and `Text Splitters` that you can use. They are included in two different python modules: `doc_intelligence.py` and `ingestion.py`.\n",
    "\n",
    "You can now use these libraries to create your advanced RAG.\n",
    "\n",
    "We provided already the libraries and the Environment variables required (you need just to populate them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, dotenv\n",
    "dotenv.load_dotenv(override=True)\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../lib')))\n",
    "\n",
    "# Setup environment\n",
    "\n",
    "# OpenAI\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_MODEL = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING = os.getenv(\"AZURE_OPENAI_EMBEDDING\")\n",
    "# Azure Search\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "# Azure AI Document Intelligence\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_KEY\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_VERSION= os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_VERSION\")\n",
    "# Azure Blob Storage\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "AZURE_STORAGE_CONTAINER = os.getenv(\"AZURE_STORAGE_CONTAINER\")\n",
    "AZURE_STORAGE_FOLDER = os.getenv(\"AZURE_STORAGE_FOLDER\")\n",
    "\n",
    "# Import Libraries\n",
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from azure.ai.documentintelligence.models import DocumentAnalysisFeature\n",
    "\n",
    "# Custom Libraries\n",
    "from its_a_rag.doc_intelligence import AzureAIDocumentIntelligenceLoader\n",
    "from its_a_rag import ingestion\n",
    "\n",
    "# Define the questions list (if you are using your own dataset you need to change this list)\n",
    "QUESTIONS = [\n",
    "  \"What are the revenues of GOOGLE in the year 2009?\",\n",
    "  \"What are the revenues and the operative margins of ALPHABET Inc. in 2022 and how it compares with the previous year?\",\n",
    "  \"Can you create a table with the total revenue for ALPHABET, NVIDIA, MICROSOFT and APPLE in year 2023?\",\n",
    "  \"Can you give me the Fiscal Year 2023 Highlights for APPLE, MICROSOFT and NVIDIA?\",\n",
    "  \"Did APPLE repurchase common stock in 2023? create a table of APPLE repurchased stock with date, numbers of stocks and values in dollars.\",\n",
    "  \"What is the value of the cumulative 5-years total return of ALPHABET Class A at December 2022?\",\n",
    "  \"What was the price of APPLE, NVIDIA and MICROSOFT stock in 23/07/2024?\",\n",
    "  \"Can you buy 10 shares of APPLE for me?\"\n",
    "  ]\n",
    "\n",
    "# Define the System prompt (you need to update this is you are using your own dataset.)\n",
    "system_prompt = \"\"\" You are a financial assistant tasked with answering questions related to the financial results of major technology companies listed on NASDAQ, \\n\n",
    "specifically Microsoft (MSFT), Alphabet Inc. (GOOGL), Nvidia (NVDA), Apple Inc. (AAPL), and Amazon (AMZN). \\n\n",
    "if you don't find the answer in the context, just say `I don't know.`\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Vector store, the embeddings client and the OpenAI Chat client\n",
    "\n",
    "Let's start creating the vector store and the embeddings client. Because we need a custom index to store the information in the way so that our retriever wil be able to get it, we have a custom function for that (create_multimodal_vectore_store).\n",
    "For the OpenAI Chat client we will simply use the one offered by langchain framework as in the Step 3 of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index for Azure Search store and Embedding (using the custom function create_multimodal_vectore_store)\n",
    "# NOTE: Remember to create the new index in Azure Search called \"itsarag-ch4-001\"\n",
    "\n",
    "search,embeddings = ingestion.create_multimodal_vector_store(\n",
    "    #   - index_name: name of the index\n",
    "    #   - azure_openai_api_key: azure openai api key\n",
    "    #   - azure_openai_endpoint: azure openai endpoint\n",
    "    #   - azure_openai_api_version: azure openai api version\n",
    "    #   - azure_openai_embedding_deployment: azure openai embedding deployment\n",
    "    #   - azure_search_endpoint: azure search endpoint\n",
    "    #   - azure_search_api_key: azure search api key\n",
    "    index_name=\"itsarag-ch4-001\",\n",
    "    azure_openai_api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_openai_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    azure_openai_api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_openai_embedding_deployment=AZURE_OPENAI_EMBEDDING,\n",
    "    azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    azure_search_api_key=AZURE_SEARCH_API_KEY)\n",
    "\n",
    "# Create the Azure OpenAI Chat Client\n",
    "llm = AzureChatOpenAI(api_key=AZURE_OPENAI_API_KEY,\n",
    "                      api_version=AZURE_OPENAI_API_VERSION,\n",
    "                      azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "                      model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "                      streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Phase\n",
    "\n",
    "As always the first step is to index the documents:\n",
    "the high level steps are:\n",
    "\n",
    "- Set Folder Path: Assign the local folder path to the variable folder.\n",
    "- List Files: Create a list of files in the specified folder.\n",
    "- Get Full Paths: Convert the list of file names to their full paths.\n",
    "- Iterate Over Files: Loop through each file in the list.\n",
    "    - Extract File Name: Extract the file name from the full path (this is required for the document loader).\n",
    "    - Load Document: Use AzureAIDocumentIntelligenceLoader to load the document with specified API credentials and settings (remember to use pre-built layout as model and the latest API version)\n",
    "    - Split Document: Split the loaded document using a custom advanced text splitter.\n",
    "    - Store Document: Add the processed documents to a multimodal vector store (using the add_documents method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  ../../data/fsi/pdf/2023 FY APPL.pdf\n",
      "Processing figures in ../../data/fsi/pdf/2023 FY APPL.pdf...\n",
      "Updating figure description 0...\n",
      "Processing:  ../../data/fsi/pdf/2023 FY GOOGL.pdf\n",
      "Processing figures in ../../data/fsi/pdf/2023 FY GOOGL.pdf...\n",
      "Updating figure description 0...\n",
      "Updating figure description 1...\n",
      "Processing:  ../../data/fsi/pdf/2023 FY AMZN.pdf\n",
      "Processing figures in ../../data/fsi/pdf/2023 FY AMZN.pdf...\n",
      "Processing:  ../../data/fsi/pdf/2023 FY NVDA.pdf\n",
      "Processing figures in ../../data/fsi/pdf/2023 FY NVDA.pdf...\n",
      "Updating figure description 0...\n",
      "Updating figure description 1...\n",
      "Updating figure description 2...\n",
      "Updating figure description 3...\n",
      "Updating figure description 4...\n",
      "Updating figure description 5...\n",
      "Processing:  ../../data/fsi/pdf/2023 FY MSFT.pdf\n",
      "Processing figures in ../../data/fsi/pdf/2023 FY MSFT.pdf...\n"
     ]
    }
   ],
   "source": [
    "# Index\n",
    "\n",
    "# Index: Load files\n",
    "\n",
    "# Get list of files in a local folder that start with \"2023\"\n",
    "folder = \"../../data/fsi/pdf\"\n",
    "files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.startswith(\"2023\")]\n",
    "files = [os.path.join(folder, f) for f in files]\n",
    "\n",
    "# For each file\n",
    "for file in files:\n",
    "    # Get the file name\n",
    "    pdf_file_name = file.split(\"/\")[-1]\n",
    "    # Index : Load the file and create a document\n",
    "    print(\"Processing: \", file)\n",
    "\n",
    "    loader = AzureAIDocumentIntelligenceLoader(\n",
    "        api_endpoint= AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT,\n",
    "        api_key= AZURE_DOCUMENT_INTELLIGENCE_API_KEY,\n",
    "        file_path=file\n",
    "    )\n",
    "    \n",
    "    # Index : Split (using advanced text splitter from the custom library)\n",
    "    split_documents = ingestion.advanced_text_splitter(\n",
    "        loader.load(), pdf_file_name)\n",
    "    # Index : Store (add_documents from the custom library)\n",
    "    search.add_documents(split_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Phase\n",
    "\n",
    "The next step is to create a retriever for the documents based on the user query.\n",
    "You should use the following parameters:\n",
    "- Search Type: Hybrid\n",
    "- number of results: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve  (as_retriever)\n",
    "retriever_multimodal = search.as_retriever(\n",
    "    search_type=\"hybrid\", k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Phase\n",
    "\n",
    "The final step is to generate the answer using the RAG model.\n",
    "We will create a Langchain chain with the following steps:\n",
    " - Retrieve the docs and get the image description if the doc matedata is an image (with get_image_description function - RunnableLambda), then pass the context and question (using RunnablePassthrough) to the next phase\n",
    " - Use the advanced multimodal Prompt function to append system messages, the context including the text, the image (if present) and the question - check RannableLambda method also here.\n",
    " - Use the OpenAI model to generate the answer\n",
    " - Parse the output and return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate\n",
    "\n",
    "# RAG pipeline\n",
    "chain_multimodal_rag = (\n",
    "    {\n",
    "        \"context\": retriever_multimodal | RunnableLambda(ingestion.get_image_description),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(ingestion.multimodal_prompt)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Solution\n",
    "\n",
    "You can test the solution by providing a question and checking the answer generated by the RAG model (invoke the Langchain chain).\n",
    "\n",
    "Try to get answer for the following questions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: What are the revenues of GOOGLE in the year 2009?\n",
      "I don't know. The context provided does not include Google's revenues for the year 2009.\n",
      "--------------------------------------------------\n",
      "QUESTION: What are the revenues and the operative margins of ALPHABET Inc. in 2022 and how it compares with the previous year?\n",
      "Alphabet Inc.'s total revenues for 2022 were **$282,836 million**, up from **$257,637 million** in 2021. Operating income in 2022 was **$74,842 million**, down from **$78,714 million** in 2021. The operating margin for 2022 was **26%**, a slight decrease from **31%** in 2021. \n",
      "\n",
      "This reflects revenue growth but a reduction in operating margins compared to the prior year.\n",
      "\n",
      "For more detailed comparisons, additional data on 2021 margins would be required.\n",
      "--------------------------------------------------\n",
      "QUESTION: Can you create a table with the total revenue for ALPHABET, NVIDIA, MICROSOFT and APPLE in year 2023?\n",
      "\n",
      "Based on the provided context, here is a table summarizing the total revenue for each company in 2023:\n",
      "\n",
      "| Company    | Total Revenue (2023) |\n",
      "|------------|-----------------------|\n",
      "| Alphabet   | $307,394 million     |\n",
      "| NVIDIA     | $60,922 million      |\n",
      "| Microsoft  | $211,915 million     |\n",
      "| Apple      | $383,285 million     |\n",
      "--------------------------------------------------\n",
      "QUESTION: Can you give me the Fiscal Year 2023 Highlights for APPLE, MICROSOFT and NVIDIA?\n",
      "\n",
      "### Fiscal Year 2023 Highlights:\n",
      "\n",
      "#### **Apple**:\n",
      "- **Total net sales**: $383.3 billion\n",
      "- **Net income**: $97.0 billion\n",
      "- **Total net sales decrease**: 3% ($11.0 billion compared to 2022) driven mainly by lower Mac and iPhone sales, partially offset by higher Services revenue.\n",
      "\n",
      "#### **Microsoft**:\n",
      "- **Microsoft Cloud revenue**: $111.6 billion, up **22%**.\n",
      "- **Dynamics products and cloud services revenue**: Increased **16%**, driven by Dynamics 365 growth of 24%.\n",
      "- **Server products and cloud services revenue**: Increased **19%**, primarily from Azure and other cloud services growth of 29%.\n",
      "- **Xbox content and services revenue**: Declined **3%**.\n",
      "- **Office 365 Commercial**: Growth of 13%.\n",
      "- **Devices revenue**: Declined **24%**.\n",
      "\n",
      "#### **NVIDIA**:\n",
      "- **Revenue**: $26.97 billion in fiscal year 2023.\n",
      "- **Gaming revenue**: $10.4 billion.\n",
      "- **Data Center revenue**: Significant growth (217% in fiscal year 2024 compared to fiscal year 2023).\n",
      "- Financial results showed marked improvement in gross margins, net income, and earnings per share from 2023 to 2024.\n",
      "\n",
      "#### Additional Note:\n",
      "There is more data for NVIDIA FY 2024 (as it spans into 2024), but highlights exclusive to FY 2023 suggest foundational growth in Data Centers and Gaming. \n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "QUESTION: Did APPLE repurchase common stock in 2023? create a table of APPLE repurchased stock with date, numbers of stocks and values in dollars.\n",
      "\n",
      "Yes, Apple repurchased common stock in 2023. Below is a table summarizing Apple's repurchases in 2023:\n",
      "\n",
      "| Date/Period                     | Number of Shares Repurchased (in millions) | Total Value (in $ billions) | Average Price Paid per Share (if available) |\n",
      "|---------------------------------|-------------------------------------------|-----------------------------|---------------------------------------------|\n",
      "| Entire Year (2023)              | 471                                       | 76.6                        | Not explicitly provided                     |\n",
      "| July 2, 2023 - August 5, 2023   | 33.864                                   | Not disclosed              | $191.62                                     |\n",
      "| August 6, 2023 - September 2, 2023 | 30.299 and 22.085 (ASRs)*                | Not disclosed              | $178.99                                     |\n",
      "| September 3, 2023 - September 30, 2023 | 20.347                                   | Not disclosed              | $176.31                                     |\n",
      "| **Total (Q3 2023)**             | 106.595                                  | Not disclosed              | -                                           |\n",
      "\n",
      "*ASRs: Accelerated Share Repurchase agreements, with final prices determined in 2024.  \n",
      "\n",
      "Notes:\n",
      "- The total repurchase value excludes excise tax under the Inflation Reduction Act of 2022. \n",
      "- Some detailed specific repurchase values and average prices beyond Q3 2023 were not disclosed in the context.\n",
      "--------------------------------------------------\n",
      "QUESTION: What is the value of the cumulative 5-years total return of ALPHABET Class A at December 2022?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The cumulative 5-year total return of Alphabet Class A at December 2022 is approximately **$200** based on the provided graph.\n",
      "--------------------------------------------------\n",
      "QUESTION: What was the price of APPLE, NVIDIA and MICROSOFT stock in 23/07/2024?\n",
      "\n",
      "\n",
      "I don't know the exact stock prices of Apple, NVIDIA, and Microsoft on July 23, 2024, as the provided context does not include that information.\n",
      "--------------------------------------------------\n",
      "QUESTION: Can you buy 10 shares of APPLE for me?\n",
      "\n",
      "I cannot buy shares for you as I am not a financial service or broker. You would need to contact a registered brokerage or financial institution to purchase Apple (AAPL) shares.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the solution\n",
    "for QUESTION in QUESTIONS:\n",
    "    print(f\"QUESTION: {QUESTION}\")\n",
    "    print(chain_multimodal_rag.invoke(QUESTION))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
